{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1sa_QJ55-fu"
   },
   "source": [
    "# **Project 3 - Q Learning**\n",
    "\n",
    "For this project, you will be tasked with both implementing and explaining key components of the Q-learning algorithm.\n",
    "\n",
    "All the code deliverables has to be provided within this notebook.\n",
    "\n",
    "# 1 - Packages\n",
    "Let's first import all the packages that you will need during this assignment.\n",
    "\n",
    "* \n",
    "[numpy](https://numpy.org/) - is the main package for scientific computing with Python\n",
    "*\n",
    "[matplotlib](https://matplotlib.org/) - is a plotting library\n",
    "*\n",
    "[gym](https://gym.openai.com/docs/) - Gym is a toolkit for developing and comparing reinforcement learning algorithms.\n",
    "*\n",
    "[gym.spaces](http://gym.openai.com/docs/) - Every environment comes with an action_space and an observation_space. These attributes are of type Space, and they describe the format of valid actions and observations.\n",
    "*\n",
    "[time](https://docs.python.org/3/library/time.html?highlight=time#module-time) - will be used to track how much time each computation takes\n",
    "*\n",
    "[copy](https://docs.python.org/3/library/copy.html) - A copy is sometimes needed so one can change one copy without changing the other.\n",
    "*\n",
    "[Threading](https://docs.python.org/3/library/threading.html) - This module constructs higher-level threading interfaces on top of the lower level thread module.\n",
    "*\n",
    "[Collections](https://docs.python.org/2/library/collections.html) - This module implements specialized container datatypes providing alternatives to Pythonâ€™s general purpose built-in containers, dict, list, set, and tuple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_PLd07ie8k1"
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Authors:\n",
    "# Nathan Margaglio (nathanmargaglio@gmail.com)                                                          \n",
    "# Mihir Hemant Chauhan (mihirhem@buffalo.edu)                       \n",
    "# Qian Cheng (qcheng2@buffalo.edu)                            \n",
    "#######################################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import gym.spaces\n",
    "import time\n",
    "import copy\n",
    "import threading\n",
    "import time\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AsLthEre8kw"
   },
   "source": [
    "`## Basic Environment\n",
    "Here we define our grid-world environment. No need to make any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1KZhxOunpbNp"
   },
   "outputs": [],
   "source": [
    "class GridEnvironment(gym.Env):\n",
    "    metadata = { 'render.modes': ['human'] }\n",
    "    \n",
    "    def __init__(self, normalize=False, size=4):\n",
    "        self.observation_space = gym.spaces.Box(0, size, (size,))\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.max_timesteps = size*2 + 1\n",
    "        self.normalize = normalize\n",
    "        self.size = size\n",
    "\n",
    "        # Generate State Transition Table\n",
    "        self.transition_matrix = []\n",
    "        for x in range(size + 1):\n",
    "            state_x = []\n",
    "            for y in range(size + 1):\n",
    "                state_y = []\n",
    "                for a in range(4):\n",
    "                    one_hot = np.zeros(4)\n",
    "                    one_hot[a] = 1\n",
    "                    state_y.append(one_hot)\n",
    "                state_x.append(state_y)\n",
    "            self.transition_matrix.append(state_x)\n",
    "            \n",
    "        \n",
    "    def transition_func(self, x, y, action, return_probs=False):\n",
    "        probs = self.transition_matrix[x][y][action]\n",
    "        if return_probs:\n",
    "            return probs\n",
    "        else:\n",
    "            return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "    def _get_distance(self, x, y):\n",
    "        return abs(x[0] - y[0]) + abs(x[1] - y[1])\n",
    "        \n",
    "    def reset(self):\n",
    "        self.timestep = 0\n",
    "        self.agent_pos = [0, 0]\n",
    "        self.goal_pos = [self.size, self.size]\n",
    "        self.state = np.zeros((self.size + 1, self.size + 1))\n",
    "        self.state[tuple(self.agent_pos)] = 1\n",
    "        self.state[tuple(self.goal_pos)] = 0.5\n",
    "        self.prev_distance = self._get_distance(self.agent_pos, self.goal_pos)\n",
    "        return np.array(self.agent_pos)/1.\n",
    "    \n",
    "    def step(self, action):\n",
    "        action_taken = self.transition_func(self.agent_pos[0], self.agent_pos[1], action)\n",
    "        self.state = np.random.choice(self.observation_space.shape[0])\n",
    "        if action_taken == 0:\n",
    "            self.agent_pos[0] += 1\n",
    "        if action_taken == 1:\n",
    "            self.agent_pos[0] -= 1\n",
    "        if action_taken == 2:\n",
    "            self.agent_pos[1] += 1\n",
    "        if action_taken == 3:\n",
    "            self.agent_pos[1] -= 1\n",
    "          \n",
    "        self.agent_pos = np.clip(self.agent_pos, 0, self.size)\n",
    "        self.state = np.zeros((self.size + 1, self.size + 1))\n",
    "        self.state[tuple(self.agent_pos)] = 1\n",
    "        self.state[tuple(self.goal_pos)] = 0.5\n",
    "        \n",
    "        current_distance = self._get_distance(self.agent_pos, self.goal_pos)\n",
    "        if current_distance < self.prev_distance:\n",
    "            reward = 1\n",
    "        elif current_distance > self.prev_distance:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = -1\n",
    "        self.prev_distance = current_distance\n",
    "        \n",
    "        self.timestep += 1\n",
    "        if self.timestep >= self.max_timesteps or current_distance == 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        info = {}\n",
    "        \n",
    "        obs = self.agent_pos\n",
    "        if self.normalize:\n",
    "            obs = obs/self.size\n",
    "        return obs, reward, done, info\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        plt.imshow(self.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hy2YHvlNe8lW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = GridEnvironment()\n",
    "obs = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bc3VOQuJF1el"
   },
   "source": [
    "## Random Agent\n",
    "This runs the environment with a random agent that just takes random actions. Neither does he learn, nor remember anything. Try to run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9XqqwQtFr8k"
   },
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.observation_space = env.observation_space\n",
    "        self.action_space = env.action_space\n",
    "\n",
    "    def policy(self, observation):\n",
    "        return np.random.choice(self.action_space.n)\n",
    "        \n",
    "    def step(self, observation, verbose=False):\n",
    "        return self.policy(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S5tBBqfF-s3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridEnvironment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-05ac064577a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridEnvironment' is not defined"
     ]
    }
   ],
   "source": [
    "env = GridEnvironment(normalize=True)\n",
    "agent = RandomAgent(env)\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "agent.epsilon = 0\n",
    "env.render()\n",
    "plt.show()\n",
    "\n",
    "while not done:\n",
    "    action = agent.step(obs, verbose=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCKzZh7u0zFJ"
   },
   "source": [
    "## Heuristic Agent\n",
    "This runs the environment with a heuristic agent. No need to make any changes. Try to run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVGLhrTG0yQp"
   },
   "outputs": [],
   "source": [
    "class HeuristicAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.observation_space = env.observation_space\n",
    "        self.action_space = env.action_space\n",
    "\n",
    "    def policy(self, observation):\n",
    "        # 0 - down\n",
    "        # 1 - up\n",
    "        # 2 - right\n",
    "        # 3 - left\n",
    "        if (observation[0] < 1.):\n",
    "            return 0\n",
    "        if (observation[1] < 1.):\n",
    "            return 2\n",
    "        return 0\n",
    "        \n",
    "    def step(self, observation, verbose=False):\n",
    "        if verbose:\n",
    "            print(observation)\n",
    "        return self.policy(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZGSRSzo07v-"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridEnvironment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a95056efb63b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHeuristicAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridEnvironment' is not defined"
     ]
    }
   ],
   "source": [
    "env = GridEnvironment(normalize=True)\n",
    "agent = HeuristicAgent(env)\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "agent.epsilon = 0\n",
    "env.render()\n",
    "plt.show()\n",
    "\n",
    "while not done:\n",
    "    action = agent.step(obs, verbose=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSjsMD6Ze8ld"
   },
   "source": [
    "## Tabular Q-Learning\n",
    "This is where you need to define policy and update Q tables.\n",
    "For policy.\n",
    "\n",
    "*  \n",
    "[np.argmax](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html) - Returns the indices of the maximum values along an axis.\n",
    "\n",
    "### Epsilon\n",
    "\n",
    "Our agent will randomly select its action at first by a certain percentage, called â€˜exploration rateâ€™ or â€˜epsilonâ€™. This is because at first, it is better for the agent to try all kinds of things before it starts to see the patterns. When it is not deciding the action randomly, the agent will predict the reward value based on the current state and pick the action that will give the highest reward. We want our agent to decrease the number of random action, as it goes, so we indroduce an exponential-decay epsilon, that eventually will allow our agent to explore the evironment. \\\\\n",
    "\n",
    "\n",
    "\n",
    "###  <font color='red'>Task 1: Implement policy function.</font>  <br>\n",
    "**Instructions:**\n",
    "- Our agent will randomly select its action at first by a certain percentage, called â€˜exploration rateâ€™ or â€˜epsilonâ€™. This is because at first, it is better for the agent to try all kinds of things before it starts to see the patterns. Select a random uniform number. If it's less than epsilon, return the random choice action space.\n",
    "- When it is not deciding the action randomly, the agent will predict the reward value based on the current state and pick the action that will give the highest reward. \n",
    "\\begin{align} \\notag\n",
    "\\pi\\left(s_{t}\\right)=\\underset{a \\in A}{\\operatorname{argmax}} Q_{\\theta}\\left(s_{t}, a\\right)\n",
    "\\end{align} \n",
    "- Return the policy\n",
    "- Please note, that the name for all the variables should start with <mark>self</mark>, thus </br> \n",
    "\n",
    "epsilon $\\rightarrow$ self.epsilon </br> \n",
    "action_space $\\rightarrow$ self.action_space\n",
    "\n",
    "###  <font color='red'>Task 2: Update Q-table</font>  <br>\n",
    "**Instructions:**\n",
    "            \\begin{align} \\notag\n",
    "            Q^{n e w}\\left(s_{t}, a_{t}\\right) \\leftarrow(1-\\alpha) \\cdot \\underbrace{Q\\left(s_{t}, a_{t}\\right)}_{\\text {old value }}+\\underbrace{\\alpha}_{\\text {learning rate }} \\cdot \\overbrace{(\\underbrace{r_{t}}_{\\text {reward }} + \\underbrace{\\gamma}_{\\text {discount factor }} \\underbrace{\\max _{a} Q\\left(s_{t+1}, a\\right)}_{a})}^{\\text {learned value }}\n",
    "            \\end{align} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l88irSuqe8lf"
   },
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, env, epsilon=1.0, lr=0.1, gamma=0.9):\n",
    "        self.env = env\n",
    "        self.observation_space = env.observation_space\n",
    "        self.action_space = env.action_space\n",
    "        q_table_dim = env.observation_space.shape[0] + 1\n",
    "        self.q_table = np.zeros((q_table_dim, q_table_dim, env.action_space.n))\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def policy(self, observation):\n",
    "      # Code for policy (Task 1) (40 points)\n",
    "        exploration_rate = np.random.uniform(0,1)\n",
    "        if(exploration_rate<self.epsilon):\n",
    "            print(\"Explore\")\n",
    "            return np.random.choice(self.action_space.n)\n",
    "        else:\n",
    "            print(\"Exploit\")\n",
    "            observation=observation.astype(int)\n",
    "            act=np.argmax(self.q_table[observation[0]][observation[1]])\n",
    "            return act\n",
    "        \n",
    "    def step(self, observation):\n",
    "        return self.policy(observation)\n",
    "        \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        state = state.astype(int)\n",
    "        next_state = next_state.astype(int)\n",
    "        # Code for updating Q Table (Task 2) (30 points)\n",
    "        self.q_table[state[0]][state[1]][action]=(1-self.lr)*self.q_table[state[0]][state[1]][action]+self.lr*(reward+self.gamma*np.max(self.q_table[next_state[0]][next_state[1]][action]))\n",
    "        \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNKDdzD3e8lj"
   },
   "source": [
    "### Training\n",
    "### Environment\n",
    "First, we initialize our environment.  The environment, loosely structured like [OpenAI's Gym Environments](https://gym.openai.com/), has three main methods: `reset`, `step` and `render`. You'll only need `reset` and `step` here.\n",
    "\n",
    "- When we call **reset**, we initialize the environment with a fresh episode. This allows us to effectively run through episodes (only needing to call reset at the beginning of an episode), but, more importantly, `reset()` returns the environment's initial state.\n",
    "\n",
    "- The **step** method accepts an action as a parameter (which, for this example, is an integer in [0, 3]), processes the action, and returns the new state, the reward for performing the action, and a boolean indicating if the run is over.\n",
    "\n",
    "### Agent\n",
    "When we initialize the agent, we must pass both a `environment` into QLearningAgent function.\n",
    "###  <font color='red'>Task 3: Implement the training algorithm</font>  <br>\n",
    "**Instructions:**\n",
    "- After initialization, pass the initial state to obs. Then check if it's already done. If done = False, you'll keep going. While it's not done, you'll need to update `state`, `action`,`reward` and `next_state`. You can get action by `step` the current state on agent. Use `copy` to record the current state. `step` the current action on environment to return the new state, the reward for performing the action, a boolean indicating if the run is over and some other information. Add the new reward on the total rewards. Use `copy` to save the new state returned by `step`. Update the `state`, `action`, `reward`, `next_state` of agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SDbl2Kue8lk",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridEnvironment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-eb99cafc5be0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# note: we do not normalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQLearningAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepisodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;31m# number of games we want the agent to play\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdelta_epsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridEnvironment' is not defined"
     ]
    }
   ],
   "source": [
    "env = GridEnvironment() # note: we do not normalize\n",
    "agent = QLearningAgent(env)\n",
    "episodes = 1000 # number of games we want the agent to play\n",
    "delta_epsilon = agent.epsilon/episodes\n",
    "\n",
    "total_rewards = []\n",
    "epsilons = [agent.epsilon]\n",
    "\n",
    "# Training Process (Task 3) (30 points)\n",
    "for i in range(episodes):\n",
    "    obs=env.reset()\n",
    "    done=False\n",
    "    print(\"The Iteration Number Is:\",i)\n",
    "    delta_epsilon = agent.epsilon/(episodes-i)\n",
    "    env.render()\n",
    "    plt.show()\n",
    "    while not done:\n",
    "        action=agent.step(obs)\n",
    "        curr=copy.copy(obs)\n",
    "        epsilons.append(agent.epsilon)\n",
    "        obs,reward,done,info=env.step(action)\n",
    "        total_rewards.append(reward)\n",
    "        next_state=copy.copy(obs)\n",
    "        agent.update(curr,action,reward,next_state)\n",
    "        agent.set_epsilon(agent.epsilon-delta_epsilon)\n",
    "        env.render()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHDJV4ZAE2l8"
   },
   "source": [
    "#### Visualize $\\epsilon$\n",
    "Plot our value of $\\epsilon$ over each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q137fw4je8ln"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x217571e4948>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Episode')\n",
    "plt.ylabel('$\\epsilon$')\n",
    "plt.plot(epsilons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30Yr74K2e8lr"
   },
   "source": [
    "#### Visualize Rewards\n",
    "Plot total_rewards per episode.  We apply a rolling mean of window $10$ to visualize easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Raqojkywe8ls"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x217570ad4c8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window = 10\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward (SMA 10)')\n",
    "plt.plot([np.mean(total_rewards[tr:tr+window]) for tr in range(window, len(total_rewards))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6wai0MeiGVG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridEnvironment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b0f4d79be36e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridEnvironment' is not defined"
     ]
    }
   ],
   "source": [
    "env = GridEnvironment()\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "agent.epsilon = 0\n",
    "env.render()\n",
    "plt.show()\n",
    "\n",
    "while not done:\n",
    "    action = agent.step(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Template of Tabular Q-Learning",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
